{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3071: DtypeWarning: Columns (4,15,40,41,43,44,74,83,84,85,86,87,97,147) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from jordan.model.Sample_MIL import InstanceModels, RaggedModels\n",
    "from jordan.model.KerasLayers import Losses, Metrics\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "from jordan.model import DatasetsUtils\n",
    "import pickle\n",
    "import logomaker\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(physical_devices[-4], True)\n",
    "#tf.config.experimental.set_visible_devices(physical_devices[-4], 'GPU')\n",
    "\n",
    "D, tcga_maf, samples = pickle.load(open('/home/janaya2/Desktop/ATGC_paper/figures/tumor_classification/data/data.pkl', 'rb'))\n",
    "\n",
    "cancerhotspots_df = pd.read_csv(\"/home/sahn33/Documents/cancerhotspots.v2.maf\",sep=\"\\t\", low_memory=True) #usecols=[\"Chromosome\",\"Start_Position\", \"End_Position\", \"Reference_Allele\",\"Tumor_Seq_Allele2\"],\n",
    "\n",
    "with open(\"publication_hotspots.vcf\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    chrom_index = [i for i, line in enumerate(lines) if line.strip().startswith(\"#CHROM\")]\n",
    "    data = lines[chrom_index[0]:]\n",
    "header = data[0].strip().split(\"\\t\")\n",
    "informations = [d.strip().split(\"\\t\") for d in data[1:]]\n",
    "publication_hotspots_df = pd.DataFrame(informations, columns=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cancerhotspots_df.drop_duplicates(subset=[\"Chromosome\",\"Start_Position\", \"End_Position\", \"Reference_Allele\",\"Tumor_Seq_Allele2\"],keep=False,inplace=True)\n",
    "\n",
    "cancerhotspots_df = cancerhotspots_df[[\"Chromosome\",\"Start_Position\", \"End_Position\", \"Reference_Allele\",\"Tumor_Seq_Allele2\"]] #\n",
    "cancerhotspots_df[\"id\"] = cancerhotspots_df.index\n",
    "\n",
    "hotspot_df_ = pd.merge(cancerhotspots_df, tcga_maf, how='right', on=[\"Chromosome\",\"Start_Position\", \"End_Position\", \"Reference_Allele\",\"Tumor_Seq_Allele2\"], suffixes=('_duplicate',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-3ce9a0ffbe25>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hotspot_df_copy['Alt'] = hotspot_df_copy['Alt'].apply(lambda x: x[:1])\n",
      "<ipython-input-3-3ce9a0ffbe25>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hotspot_df_copy['Ref'] = hotspot_df_copy['Ref'].apply(lambda x: x[:1])\n",
      "<ipython-input-3-3ce9a0ffbe25>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hotspot_df_copy['Start_Position'] = hotspot_df_copy['Start_Position'].apply(lambda x: str(x))\n"
     ]
    }
   ],
   "source": [
    "publication_hotspots_df.drop_duplicates(subset=[\"#CHROM\",\"POS\",\"REF\",\"ALT\"],keep=False,inplace=True)\n",
    "\n",
    "hotspot_df_copy = hotspot_df_\n",
    "hotspot_df_copy = hotspot_df_copy[[\"Chromosome\",\"Start_Position\",\"Ref\",\"Alt\",\"id\"]] #\n",
    "hotspot_df_copy['Alt'] = hotspot_df_copy['Alt'].apply(lambda x: x[:1])\n",
    "hotspot_df_copy['Ref'] = hotspot_df_copy['Ref'].apply(lambda x: x[:1])\n",
    "hotspot_df_copy['Start_Position'] = hotspot_df_copy['Start_Position'].apply(lambda x: str(x))\n",
    "publication_hotspots_df[\"my_index\"] = publication_hotspots_df.index\n",
    "hotspot_df_merge_cols = [\"Chromosome\",\"Start_Position\",\"Ref\",\"Alt\"]\n",
    "publication_hotspots_df_merge_cols = [\"#CHROM\",\"POS\",\"REF\",\"ALT\"]\n",
    "\n",
    "hotspot_df = pd.merge(publication_hotspots_df, hotspot_df_copy, how='right', right_on = hotspot_df_merge_cols, left_on = publication_hotspots_df_merge_cols, suffixes=('_duplicate',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcga_maf['indel'] = np.where((tcga_maf['Variant_Classification'] == 'Frame_Shift_Del') |\n",
    "                             (tcga_maf['Variant_Classification'] == 'Frame_Shift_Ins') |\n",
    "                             (tcga_maf['Variant_Classification'] == 'In_Frame_Del') |\n",
    "                             (tcga_maf['Variant_Classification'] == 'In_Frame_Ins'),\n",
    "                             True, False)\n",
    "#print(tcga_maf['indel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pandas/core/indexing.py:1719: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "strand_emb_mat = np.concatenate([np.zeros(2)[np.newaxis, :], np.diag(np.ones(2))], axis=0)\n",
    "D['strand_emb'] = strand_emb_mat[D['strand']]\n",
    "\n",
    "###\n",
    "# filtering the NCI-T labels (https://livejohnshopkins-my.sharepoint.com/:x:/r/personal/abaras1_jh_edu/_layouts/15/doc2.aspx?sourcedoc=%7B5f92f0fc-ec6c-40d5-ab17-0d3345f9f2c2%7D&action=edit&activeCell=%27Sheet1%27!B21&wdinitialsession=e072a38f-57c8-4c1f-885b-efaefcc81d35&wdrldsc=2&wdrldc=1&wdrldr=AccessTokenExpiredWarning%2CRefreshingExpiredAccessT)\n",
    "ncit_labels_kept = ['Muscle-Invasive Bladder Carcinoma','Infiltrating Ductal Breast Carcinoma',\n",
    "                    'Invasive Lobular Breast Carcinoma','Cervical Squamous Cell Carcinoma',\n",
    "                    'Colorectal Adenocarcinoma','Glioblastoma','Head and Neck Squamous Cell Carcinoma',\n",
    "                    'Clear Cell Renal Cell Carcinoma','Papillary Renal Cell Carcinoma','Astrocytoma',\n",
    "                    'Oligoastrocytoma','Oligodendroglioma','Hepatocellular Carcinoma','Lung Adenocarcinoma',\n",
    "                    'Lung Squamous Cell Carcinoma','Ovarian Serous Adenocarcinoma','Adenocarcinoma, Pancreas',\n",
    "                    'Paraganglioma','Pheochromocytoma','Prostate Acinar Adenocarcinoma','Colorectal Adenocarcinoma',\n",
    "                    'Desmoid-Type Fibromatosis','Leiomyosarcoma','Liposarcoma','Malignant Peripheral Nerve Sheath Tumor',\n",
    "                    'Myxofibrosarcoma','Synovial Sarcoma','Undifferentiated Pleomorphic Sarcoma',\n",
    "                    'Cutaneous Melanoma','Gastric Adenocarcinoma','Testicular Non-Seminomatous Germ Cell Tumor',\n",
    "                    'Testicular Seminoma','Thyroid Gland Follicular Carcinoma','Thyroid Gland Papillary Carcinoma',\n",
    "                    'Endometrial Endometrioid Adenocarcinoma','Endometrial Serous Adenocarcinoma']\n",
    "idx_filter = samples['NCI-T Label'].isin(ncit_labels_kept)\n",
    "ncit_samples = samples.loc[idx_filter]\n",
    "PCPG_ncit = ['Paraganglioma','Pheochromocytoma']\n",
    "SARC_ncit = ['Desmoid-Type Fibromatosis','Leiomyosarcoma','Liposarcoma','Malignant Peripheral Nerve Sheath Tumor',\n",
    "             'Myxofibrosarcoma','Synovial Sarcoma','Undifferentiated Pleomorphic Sarcoma']\n",
    "TGCT_ncit = ['Testicular Non-Seminomatous Germ Cell Tumor','Testicular Seminoma']\n",
    "ncit_samples.loc[ncit_samples['NCI-T Label'].isin(PCPG_ncit), 'NCI-T Label'] = 'PCPG'\n",
    "ncit_samples.loc[ncit_samples['NCI-T Label'].isin(SARC_ncit), 'NCI-T Label'] = 'SARC'\n",
    "ncit_samples.loc[ncit_samples['NCI-T Label'].isin(TGCT_ncit), 'NCI-T Label'] = 'TGCT'\n",
    "\n",
    "#samples = ncit_samples\n",
    "A = ncit_samples['NCI-T Label'].astype('category')\n",
    "###\n",
    "\n",
    "##each instance has an associated sample index so we need to group the instances for each sample together\n",
    "##the sample dataframe had its index reset so the indexes start at 0 and are concurrent, if you subset the sample dataframe then you'll have to only generate indexes for those samples\n",
    "indexes = [np.where(D['sample_idx'] == idx) for idx in np.arange(samples.shape[0])[idx_filter]]\n",
    "\n",
    "##the sequence encoder has five inputs\n",
    "five_p = np.array([D['seq_5p'][i] for i in indexes], dtype='object')\n",
    "three_p = np.array([D['seq_3p'][i] for i in indexes], dtype='object')\n",
    "ref = np.array([D['seq_ref'][i] for i in indexes], dtype='object')\n",
    "alt = np.array([D['seq_alt'][i] for i in indexes], dtype='object')\n",
    "strand = np.array([D['strand_emb'][i] for i in indexes], dtype='object')\n",
    "hotspots = np.array([~pd.isna(hotspot_df[\"my_index\"]).values[i] for i in indexes], dtype='object')\n",
    "indels = np.array([tcga_maf['indel'].values[i] for i in indexes], dtype='object')\n",
    "\n",
    "##when we evaluate the model we don't want to be dropping out any instances\n",
    "five_p_loader_eval = DatasetsUtils.Map.FromNumpy(five_p, tf.int16)\n",
    "three_p_loader_eval = DatasetsUtils.Map.FromNumpy(three_p, tf.int16)\n",
    "ref_loader_eval = DatasetsUtils.Map.FromNumpy(ref, tf.int16)\n",
    "alt_loader_eval = DatasetsUtils.Map.FromNumpy(alt, tf.int16)\n",
    "strand_loader_eval = DatasetsUtils.Map.FromNumpy(strand, tf.float32)\n",
    "\n",
    "#A = samples['type'].astype('category')\n",
    "classes = A.cat.categories.values\n",
    "##integer values for random forest\n",
    "classes_onehot = np.eye(len(classes))[A.cat.codes]\n",
    "y_label = classes_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##you should have the context\n",
    "test_idx, weights = pickle.load(open('/home/mlee276/Desktop/TCGA-ML-main/results/mil_contexts_weights.pkl', 'rb'))\n",
    "\n",
    "sequence_encoder = InstanceModels.VariantSequence(6, 4, 2, [16, 16, 16, 16], fusion_dimension=256)\n",
    "mil = RaggedModels.MIL(instance_encoders=[sequence_encoder.model], sample_encoders=[], output_dims=[y_label.shape[-1]], output_types=['other'], instance_layers=[512], mil_hidden=[256, 128, 64], attention_layers=[64, 16], dropout=.2, instance_dropout=.3, regularization=0, input_dropout=.4)\n",
    "\n",
    "attention_weights = []\n",
    "embedding_weights = []\n",
    "idx_test_all = []\n",
    "for idx_test, fold_weights in zip(test_idx, weights):\n",
    "    mil.model.set_weights(fold_weights)\n",
    "    ds_test = tf.data.Dataset.from_tensor_slices(((\n",
    "                                                       five_p_loader_eval(idx_test),\n",
    "                                                       three_p_loader_eval(idx_test),\n",
    "                                                       ref_loader_eval(idx_test),\n",
    "                                                       alt_loader_eval(idx_test),\n",
    "                                                       strand_loader_eval(idx_test),\n",
    "                                                   ),\n",
    "    ))\n",
    "    ds_test = ds_test.batch(len(idx_test), drop_remainder=False)\n",
    "    attention_weights.extend(mil.attention_model.predict(ds_test).to_list())\n",
    "    idx_test_all.extend(idx_test)\n",
    "    embedding_weights.append(mil.model.get_weights())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##the attention weights are grouped by sample and in the order of idx_test of each fold.\n",
    "##I believe Alex wants you to take samples in the test data which are correctly predicted, grab their sample indexes, and look at their attention weights.\n",
    "##Grab the highest attention weight indexes, and then make seq logos.\n",
    "\n",
    "#1. For given cancer type:\n",
    "#2. In the test data (ds_test), get the samples that are correctly predicted\n",
    "#3. Use the sample indexes to get their attention weights\n",
    "#4. Get the weight indexes with weights > 0.8\n",
    "#5. Transform and sum them to make the position weight matrix to make the seq logo.\n",
    "\n",
    "# Get MIL predictions\n",
    "test_idx, mil_predictions = pickle.load(open('/home/mlee276/Desktop/TCGA-ML-main/results/mil_contexts_predictions.pkl', 'rb'))\n",
    "mil_predictions_labels = np.argmax(mil_predictions, axis=-1)\n",
    "# Get true labels\n",
    "y_strat = np.argmax(y_label, axis=-1)\n",
    "correct = (y_strat[np.concatenate(test_idx)])\n",
    "\n",
    "hotspots_reordered = hotspots[idx_test_all] ### can only call this once or else the order gets mixed. \n",
    "indels_reordered = indels[idx_test_all]\n",
    "\n",
    "#idx = 0\n",
    "#attention_weights_ = np.array(attention_weights[idx]).flatten()\n",
    "#hotspot_attention_weights = np.expand_dims(attention_weights_, axis=0)[:,hotspots[idx]][0]\n",
    "#non_hotspot_attention_weights = np.expand_dims(attention_weights_, axis=0)[:,~hotspots[idx]][0]\n",
    "\n",
    "def get_position_weight_matrix(class_num, sequence):\n",
    "    # Get indexes of correct predictions\n",
    "    correct_predictions_idx = []\n",
    "    for i in range(len(correct)):\n",
    "        if correct[i] == mil_predictions_labels[i] and correct[i] == class_num:\n",
    "            correct_predictions_idx.append(i)\n",
    "            \n",
    "    matrix = []\n",
    "    for idx in correct_predictions_idx:\n",
    "        sample_attention_weights = np.concatenate(attention_weights[idx])\n",
    "        matrix.append(sequence[idx_test_all][idx][sample_attention_weights > .9][:, :, 0]) \n",
    "    \n",
    "    return matrix\n",
    "\n",
    "def get_position_weight_hotspots(class_num, sequence):\n",
    "    # Get indexes of correct predictions\n",
    "    correct_predictions_idx = []\n",
    "    for i in range(len(correct)):\n",
    "        if correct[i] == mil_predictions_labels[i] and correct[i] == class_num:\n",
    "            correct_predictions_idx.append(i)\n",
    "            \n",
    "    all_sample_attention_weights = []\n",
    "    hotspot_attention_weights = []\n",
    "    non_hotspot_attention_weights = []\n",
    "    for idx in correct_predictions_idx:\n",
    "        sample_attention_weights = np.concatenate(attention_weights[idx])\n",
    "        \n",
    "        hotspot_attention_weights.append(np.expand_dims(sample_attention_weights, axis=0)[:,hotspots_reordered[idx]][0])\n",
    "        non_hotspot_attention_weights.append(np.expand_dims(sample_attention_weights, axis=0)[:,~hotspots_reordered[idx]][0])\n",
    "        \n",
    "        all_sample_attention_weights.append(sample_attention_weights)\n",
    "    \n",
    "    return all_sample_attention_weights, hotspot_attention_weights, non_hotspot_attention_weights\n",
    "\n",
    "def get_position_weight_indels(class_num, sequence):\n",
    "    # Get indexes of correct predictions\n",
    "    correct_predictions_idx = []\n",
    "    for i in range(len(correct)):\n",
    "        if correct[i] == mil_predictions_labels[i] and correct[i] == class_num:\n",
    "            correct_predictions_idx.append(i)\n",
    "            \n",
    "    all_sample_attention_weights = []\n",
    "    indel_attention_weights = []\n",
    "    non_indel_attention_weights = []\n",
    "    for idx in correct_predictions_idx:\n",
    "        sample_attention_weights = np.concatenate(attention_weights[idx])\n",
    "        \n",
    "        indel_attention_weights.append(np.expand_dims(sample_attention_weights, axis=0)[:,indels_reordered[idx]][0])\n",
    "        non_indel_attention_weights.append(np.expand_dims(sample_attention_weights, axis=0)[:,~indels_reordered[idx]][0])\n",
    "        \n",
    "        all_sample_attention_weights.append(sample_attention_weights)\n",
    "    \n",
    "    return all_sample_attention_weights, indel_attention_weights, non_indel_attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, 'Gene HotSpots Attention Weight Distribution (orange is hotspots)')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grid\n",
    "%matplotlib\n",
    "fig,ax = plt.subplots(3,3)\n",
    "for i in range(9):\n",
    "    i = i+18\n",
    "    t_, h_, nh_ = get_position_weight_hotspots(i, five_p) #get_position_weight_hotspots(i,genes)\n",
    "    c1 = 0;c2 = 0;c3 = 0\n",
    "    for n in t_:\n",
    "        c1 += len(n)\n",
    "    for n in h_:\n",
    "        c2 += len(n)\n",
    "    for n in nh_:\n",
    "        c3 += len(n)\n",
    "    #print(\"all wieghts: \" + str(c1))\n",
    "    #print(\"hotspot weights: \" + str(np.round_(100*c2/c1, 3)) + \"%\")\n",
    "    #print(\"non hotpsot weights: \" + str(np.round_(100*c3/c1, 3)) + \"%\")\n",
    "    perc_hotspot = str(np.round_(100*c2/c1, 3))\n",
    "\n",
    "    bin_nums = 200\n",
    "    hotspot_att_weights = []\n",
    "    for weights in h_:\n",
    "        hotspot_att_weights.extend(weights)\n",
    "    non_hotspot_att_weights = []\n",
    "    for weights in nh_:\n",
    "        non_hotspot_att_weights.extend(weights)\n",
    "\n",
    "    i =i-18\n",
    "    #fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax[i//3,i%3].hist(non_hotspot_att_weights, bins=bin_nums, label=\"non hotspots attention weights\")\n",
    "    ax[i//3,i%3].hist(hotspot_att_weights, bins=bin_nums, label=\"hotspots attention weights\")\n",
    "    ax[i//3,i%3].set_xlabel('attention weights')\n",
    "    ax[i//3,i%3].set_ylabel('Count')\n",
    "    ax[i//3,i%3].set_title(classes[i+18] + \"; \" + perc_hotspot + \"%\", fontsize=8)\n",
    "#fig.legend()\n",
    "fig.suptitle(\"Gene HotSpots Attention Weight Distribution (orange is hotspots)\")\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
