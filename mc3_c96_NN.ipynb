{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the mc3 dataset\n",
    "df_mc3 = pd.read_csv(\"mc3.v0.2.8.PUBLIC.maf\",sep=\"\\t\",usecols=[\"Gene\",\"Tumor_Sample_Barcode\"],low_memory=True)\n",
    "df_mc3 = df_mc3.groupby(['Tumor_Sample_Barcode',\"Gene\"]).size().unstack(fill_value=0)\n",
    "mc3 = df_mc3.to_numpy()\n",
    "mc3 = np.column_stack((mc3,df_mc3.index.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the c96 dataset\n",
    "df_96 = pd.read_csv(\"WES_TCGA.96.csv\").T\n",
    "c96 = df_96.to_numpy()\n",
    "c96 = np.column_stack((c96,df_96.index.values))[2:]\n",
    "\n",
    "for i in c96:\n",
    "    i[-1] = i[-1][i[-1].index(\":\")+2:]\n",
    "    \n",
    "c96_last = np.copy(c96[:,-1])\n",
    "\n",
    "mc3_dict = {}\n",
    "for i in mc3:\n",
    "    mc3_dict[i[-1]] = i[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label the mc3 and c96 datasets\n",
    "jsonFile = json.load(open(\"cases.2020-02-28.json\",\"r\"))\n",
    "def runJson(submitter_id):\n",
    "    for i in jsonFile:\n",
    "        if(submitter_id == i[\"submitter_id\"]):\n",
    "            return i[\"project\"][\"project_id\"]\n",
    "    print(\"ERROR: \" + str(submitter_id))\n",
    "    return False\n",
    "\n",
    "mc3_labeled = np.copy(mc3)\n",
    "c96_labeled = np.copy(c96)\n",
    "for i in mc3_labeled:\n",
    "    i[-1] = runJson(i[-1][:12])\n",
    "for i in c96_labeled:\n",
    "    i[-1] = runJson(i[-1][:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the top ten cancers from the mc3 dataset\n",
    "counts = {}\n",
    "\n",
    "for i in mc3_labeled:\n",
    "    tumorName = i[-1]\n",
    "    if(tumorName in counts):\n",
    "        counts[tumorName] = counts[tumorName] + 1\n",
    "    else:\n",
    "        counts[tumorName] = 1\n",
    "        \n",
    "print(sorted(counts.items(), key=lambda x: x[1]))\n",
    "sumvar = 0\n",
    "for key,val in counts.items():\n",
    "    sumvar = sumvar + counts[key]\n",
    "    \n",
    "print(sumvar)\n",
    "\n",
    "topTen = [\"TCGA-LUAD\",\"TCGA-UCEC\", \"TCGA-UCEC\", \"TCGA-LGG\",  \"TCGA-HNSC\", \"TCGA-THCA\", \"TCGA-PRAD\"\n",
    "          , \"TCGA-LUSC\",\"TCGA-SKCM\",\"TCGA-STAD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate top ten cancers in both datasets.\n",
    "mc3_labeled_top = []\n",
    "for i in mc3_labeled:\n",
    "    if(i[-1] in topTen):\n",
    "        mc3_labeled_top.append(i)\n",
    "        \n",
    "sumagain = 0\n",
    "for i in topTen:\n",
    "    sumagain = sumagain + counts[i]\n",
    "\n",
    "mc3_labeled_top = np.array(mc3_labeled_top)\n",
    "\n",
    "c96_labeled_top = []\n",
    "for i in c96_labeled:\n",
    "    if(i[-1] in topTen):\n",
    "        c96_labeled_top.append(i)\n",
    "        \n",
    "sumagain = 0\n",
    "\n",
    "for i in topTen:\n",
    "    sumagain = sumagain + counts[i]\n",
    "    \n",
    "c96_labeled_top = np.array(c96_labeled_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data to x and y (input and labels)\n",
    "x_mc3 = mc3_labeled_top[:,0:-1]\n",
    "# extract tumor type\n",
    "y_mc3 = mc3_labeled_top[:,-1]\n",
    "typeToNumber = {}\n",
    "for i in range(len(topTen)):\n",
    "    typeToNumber[topTen[i]] = i\n",
    "newYList = []\n",
    "for i in y_mc3:\n",
    "    newYList.append(typeToNumber[i])\n",
    "    \n",
    "y_mc3 = np.array(newYList)\n",
    "\n",
    "x_c96 = c96_labeled_top[:,0:-1]\n",
    "# extract tumor type\n",
    "y_c96 = c96_labeled_top[:,-1]\n",
    "typeToNumber = {}\n",
    "for i in range(len(topTen)):\n",
    "    typeToNumber[topTen[i]] = i\n",
    "newYList = []\n",
    "for i in y_c96:\n",
    "    newYList.append(typeToNumber[i])\n",
    "    \n",
    "y_c96 = np.array(newYList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_mc3.shape)\n",
    "print(x_c96.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign which type of data to use\n",
    "x = x_mc3\n",
    "y = y_mc3\n",
    "\n",
    "# determine the number of input features\n",
    "n_features = x.shape[1]\n",
    "input_layer = tf.keras.layers.Input(shape=((n_features, )))\n",
    "dropout_layer_1 = tf.keras.layers.Dropout(0.5)(input_layer) # 0.5 for mc3\n",
    "hidden_layer_1 = tf.keras.layers.Dense(128, activation='relu', \n",
    "                                       kernel_regularizer=regularizers.l2(0.025))(dropout_layer_1) \n",
    "dropout_layer_2 = tf.keras.layers.Dropout(0.5)(hidden_layer_1) # 0.5 for mc3\n",
    "hidden_layer_2 = tf.keras.layers.Dense(64, activation='relu', \n",
    "                                       kernel_regularizer=regularizers.l2(0.02))(dropout_layer_2) \n",
    "dropout_layer_3 = tf.keras.layers.Dropout(0.5)(hidden_layer_2) # 0.5 for mc3\n",
    "hidden_layer_3 = tf.keras.layers.Dense(64,  activation='relu', \n",
    "                                       kernel_regularizer=regularizers.l2(0.02))(dropout_layer_3)\n",
    "dropout_layer_4 = tf.keras.layers.Dropout(0.5)(hidden_layer_3) # 0.5 for mc3\n",
    "output_layer = tf.keras.layers.Dense(10,  activation='softmax')(dropout_layer_4) #(hidden_layer_2)\n",
    "# model\n",
    "model = tf.keras.Model(inputs=[input_layer], outputs=[output_layer])\n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)]\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# determine the number of input features\n",
    "n_features_c96 = x_c96.shape[1]\n",
    "input_layer_c96 = tf.keras.layers.Input(shape=((n_features_c96, )))\n",
    "dropout_layer_1_c96 = tf.keras.layers.Dropout(0.2)(input_layer_c96) \n",
    "hidden_layer_1_c96 = tf.keras.layers.Dense(128, activation='relu', \n",
    "                                       kernel_regularizer=regularizers.l2(0.025))(dropout_layer_1_c96) \n",
    "dropout_layer_2_c96 = tf.keras.layers.Dropout(0.2)(hidden_layer_1_c96)\n",
    "hidden_layer_2_c96 = tf.keras.layers.Dense(64, activation='relu', \n",
    "                                       kernel_regularizer=regularizers.l2(0.02))(dropout_layer_2_c96) \n",
    "dropout_layer_3_c96 = tf.keras.layers.Dropout(0.2)(hidden_layer_2_c96) \n",
    "hidden_layer_3_c96 = tf.keras.layers.Dense(64,  activation='relu', \n",
    "                                       kernel_regularizer=regularizers.l2(0.02))(dropout_layer_3_c96)\n",
    "dropout_layer_4_c96 = tf.keras.layers.Dropout(0.2)(hidden_layer_3_c96) \n",
    "output_layer_c96 = tf.keras.layers.Dense(10,  activation='softmax')(dropout_layer_4_c96) \n",
    "# model\n",
    "model_c96 = tf.keras.Model(inputs=[input_layer_c96], outputs=[output_layer_c96])\n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)]\n",
    "# compile the model\n",
    "model_c96.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(x, y, test_size, val_size):\n",
    "    # Create train/test split\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=test_size, stratify=y)\n",
    "    # Create validation split from train split\n",
    "    X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, test_size=val_size, stratify=Y_train)\n",
    "    # convert\n",
    "    X_train = np.asarray(X_train).astype(np.float32)\n",
    "    Y_train = np.asarray(Y_train).astype(np.float32)\n",
    "    X_valid = np.asarray(X_valid).astype(np.float32)\n",
    "    Y_valid = np.asarray(Y_valid).astype(np.float32)\n",
    "    X_test = np.asarray(X_test).astype(np.float32)\n",
    "    Y_test = np.asarray(Y_test).astype(np.float32)\n",
    "    \n",
    "    return X_train, Y_train, X_valid, Y_valid, X_test, Y_test\n",
    "\n",
    "test_accuracy = []\n",
    "test_loss = []\n",
    "val_accuracy = []\n",
    "val_loss = []\n",
    "con_mats = []\n",
    "models = []\n",
    "n_repeat = 1\n",
    "y_pred_cross_vals = []\n",
    "\n",
    "# k-fold stratify\n",
    "for k in range(n_repeat):\n",
    "    # get data sets for training and testing\n",
    "    X_train, Y_train, X_valid, Y_valid, X_test, Y_test = data_split(x, y, 0.25, 0.25)\n",
    "    #X_train_mc3, Y_train_mc3, X_valid_mc3, Y_valid_mc3, X_test_mc3, Y_test_mc3 = data_split(x_mc3, y_mc3, 0.25, 0.25)\n",
    "    #X_train_c96, Y_train_c96, X_valid_c96, Y_valid_c96, X_test_c96, Y_test_c96 = data_split(x_c96, y_c96, 0.25, 0.25)\n",
    "    \n",
    "    # fit the model, larger batch size, validate \n",
    "    history = model.fit(X_train, Y_train, validation_data=(X_valid, Y_valid), \n",
    "                        epochs=150, callbacks=callbacks, batch_size=120, verbose=1)\n",
    "    \n",
    "    # evaluate the model using history\n",
    "    loss, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    test_accuracy.append(acc)\n",
    "    test_loss.append(loss)\n",
    "    history = history.history\n",
    "    val_accuracy.append(history['val_accuracy'][-1])\n",
    "    val_loss.append(history['val_loss'][-1])\n",
    "    \n",
    "    # confusion matrix\n",
    "    Y_pred_all_labels = model.predict(X_test)\n",
    "    Y_pred = np.argmax(Y_pred_all_labels,axis=1)\n",
    "    con_mat = tf.math.confusion_matrix(labels=Y_test, predictions=Y_pred).numpy()\n",
    "    con_mats.append(con_mat)\n",
    "    \n",
    "    # add model to list\n",
    "    models.append(model)\n",
    "    \n",
    "    # storing X_test, Y_test, Y_pred_all_labels, Y_pred\n",
    "    y_pred_cross_vals.append((X_test, Y_test, Y_pred_all_labels, Y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test accuracy: \" + str(np.average(np.array(test_accuracy))))\n",
    "print(\"test loss: \" + str(np.average(np.array(test_loss))))\n",
    "print(\"val accuracy: \" + str(np.average(np.array(val_accuracy))))\n",
    "print(\"val loss: \" + str(np.average(np.array(val_loss))))\n",
    "\n",
    "con_mats_sum = [[0]*10]*10\n",
    "for n in range(len(con_mats)):\n",
    "    con_mats_sum = [[con_mats_sum[i][j] + (con_mats[n])[i][j]  for j in range(len(con_mats_sum[0]))] for i in range(len(con_mats_sum))]\n",
    "\n",
    "print(\"Confusion matrix sum: \")\n",
    "print('\\n'.join([''.join(['{:4}'.format(item) for item in row]) \n",
    "      for row in con_mats_sum]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
